{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Many Challenges of ML.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNc76OR6Yehu1G1QEeG4UFK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hyunul/MLDL/blob/main/Woojin_Many_Challenges_of_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. 부족한 양의 데이터 (데이터 불균형)\n",
        "1) 문제사항\n",
        " - 간단한 문제에 대해서도 수천에서 수백만개의 예가 필요함.\n",
        "\n",
        "2) 해결방법\n",
        " - 가상의 새로운 데이터를 생성하여 학습시키는 방법 (GAN)\n",
        " - 정의된 목적함수에 가중치를 다르게 주는 방법 ex) 강아지 한번 오답의 페널티 > 도마뱀 열번 오답의 페널티\n",
        "\n",
        "#2. 낮은 품질의 데이터\n",
        "1) 문제사항\n",
        " - 데이터의 품질이 높을수록 실제로 활용될 확률이 높아짐.\n",
        " - 생각보다 낮은 품질의 데이터가 많음.\n",
        "\n",
        "2) 해결방법\n",
        " - 충분한 양의 데이터, 데이터 자체의 오류가 적음, 관계형 DB형식을 잘 지킴, 수치형 DB형식을 많이 보유함, 활용 목적에 적합함 등의 조건을 만족하는 데이터를 수집함.\n",
        "\n",
        "#3. 관계없는 피처\n",
        "*피처 : 데이터의 특성을 나타내는 것으로 데이터 표에서 열(colum)을 나타냄.\n",
        "\n",
        " 1) 문제사항\n",
        "  - 학습 데이터에 관련된 기능이 충분히 포함되어 있고 관련없는 기능이 너무 많지 않은 경우\n",
        "\n",
        "2) 해결방법\n",
        "  - 특징 추출 : 기존 피처들을 결합하여 보다 유용한 피처를 생성함.\n",
        "  - 새 데이터를 수집하여 새 기능을 생성함.\n",
        "\n",
        "#4. 오버피팅 (Overfitting) = high variance\n",
        "1) 문제사항\n",
        " - 모델의 파라미터들을 학습 데이터에 너무 가깝게 맞췄을 때 발생하는 현상.\n",
        " - 많은 공통특성 이외에 지엽적인 특성까지 반영하여, 새로운 데이터에 대해서는 예측하지 못하는 모델.\n",
        "\n",
        "2) 해결방법\n",
        " - 데이터 살피기 : 데이터에서 중요한 통계치들을 살핀다. pandas의 groupby와 같은 메서드를 사용하여 집단별 통계치를 보는 것은 필수다. 이것이 곧 학습하게 될 패턴이기 때문. \"시각화\"를 시키면 도움이 많이 됨.\n",
        " - 적절하게 수집된 데이터인가? : 수집된 데이터가 특정한 곳에서만 적용되는 것이라면 보편적으로 사용할 수 없는 모델.\n",
        " - 학습 데이터 보강 : 케이스를 \"조작적으로\" 추가시켜서 다양한 케이스를 확보하여 오버피팅을 줄이는 것이 목표. ex) 동물 사진 분류 모델에 온전한 사진뿐만 아니라 찌그러지거나 회전된 수정본들을 함께 학습시킴.\n",
        " - 학습 데이터에 포함될 특성 제한시키기 : 어떤 특성이 모델에 과한 영향을 미치는 경우에 오히려 해당 특성을 제거하고 모델을 학습시킨다. \"Garbage In, Garbage Out\"\n",
        "\n",
        "#5. 언더피팅 (Underfitting) = high bias\n",
        " 1) 문제사항\n",
        "  - 모델의 파라미터를 학습 데이터에 너무 멀게 맞췄을 때 발생하는 현상.\n",
        "  - 많은 공통특성 중 일부 특성만 반영하여 새로운 데이터도 막 예측해버리는 모델.\n",
        "\n",
        " 2) 해결방법\n",
        "  - feature를 더 많이 반영 > variance 높히기\n",
        "  - variance가 높은 머신러닝 모델 사용 : Decision Tree, kNN, SVM 모델 사용\n",
        "\n",
        "#6. HyperParameter : 모델링할때 사용자가 직접 세팅해주는 값\n",
        "#7. DataMismatch\n",
        " 1) 문제사항\n",
        "  - 학습 데이터와 개발 데이터 간의 차이 (오류 평가의 목적)\n",
        " 2) 해결방법\n",
        "  - 학습 데이터와 개발 데이터 사이에 어떤 데이터 특성이 다른지 이해하기.\n",
        "  - 알고리즘 상에서 문제가 발생하는 개발 데이터에 조금 더 적합한 학습 데이터를 수집하기.\n",
        "\n",
        " \n"
      ],
      "metadata": {
        "id": "GHFf9GUN2xDc"
      }
    }
  ]
}